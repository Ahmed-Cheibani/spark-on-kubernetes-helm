# Default values for spark-services.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

tags:
  livy: true
  jupyter: true
  historyserver: false
  jupyterhub: false

nameOverride: ""
fullnameOverride: ""

livy:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  rbac:
    create: true
  service:
    additionalPorts:
    - name: rpc10000
      port: 10000
    - name: rpc10001
      port: 10001
    - name: rpc10002
      port: 10002
    - name: rpc10003
      port: 10003
    - name: rpc10004
      port: 10004
    - name: rpc10005
      port: 10005
    - name: rpc10006
      port: 10006
    - name: rpc10007
      port: 10007
    - name: rpc10008
      port: 10008
    - name: rpc10009
      port: 10009
  ingress:
    enabled: false

jupyter:
  livyEndpoint: "http://spark-cluster-livy:80" # is OK if you install chart with name `spark-cluster`
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  ingress:
    enabled: false

historyserver:
  image:
    repository: sasnouskikh/history-server
    tag: 2.4.0-lightbend
  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: false
    # annotations:
    #   kubernetes.io/ingress.class: nginx
    #   kubernetes.io/tls-acme: "true"
    #
    #   nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
    #   nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    #   or
    #   nginx.ingress.kubernetes.io/auth-type: basic
    #   nginx.ingress.kubernetes.io/auth-secret: auth-secret
    #   nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
    #
    #   nginx.ingress.kubernetes.io/rewrite-target: /$1
    #   nginx.ingress.kubernetes.io/proxy-redirect-from: http://$host/history/
    #   nginx.ingress.kubernetes.io/proxy-redirect-to: /history-server/history/
    #   nginx.ingress.kubernetes.io/configuration-snippet: |
    #     proxy_set_header Accept-Encoding ""; # disable compression
    #     sub_filter_last_modified off;
    #     # Adding a `base href` and stripping the leading `/` from href/src tightly covers most all URL
    #     sub_filter '<head>' '<head> <base href="/history-server/">'; # add base url
    #     sub_filter 'href="/' 'href="'; # remove absolute URL path so base url applies
    #     sub_filter 'src="/' 'src="'; # remove absolute URL path so base url applies
    #
    #     sub_filter '/{{num}}/jobs/' '/jobs/';
    #
    #     sub_filter "setUIRoot('')" "setUIRoot('/history-server')"; # Set UI root for JS scripts
    #     sub_filter "document.baseURI.split" "document.documentURI.split"; # Executors page issue fix
    #
    #     sub_filter_once off;
    #     sub_filter_types text/html text/css text/javascript application/javascript; # Specify filter types to prevent processing all files
    # path: /history-server/?(.*)
    # hosts:
    # - cluster.example.com
    # tls:
    # - secretName: spark-cluster-tls
    #   hosts:
    #   - cluster.example.com

# pvc:
#   enablePVC: false
# nfs:
#   enableExampleNFS: false
# wasbs:
#   enableWASBS: true
#   sasKeyMode: true
#   secret: spark-history-server-secret
#   logDirectory: wasbs:///history-server
#
# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#       - matchExpressions:
#         - key: autoscale-retain
#           operator: In
#           values:
#           - "true"


jupyterhub:

  ingress:
    enabled: false
    # annotations:
    #   kubernetes.io/ingress.class: nginx
    #   kubernetes.io/tls-acme: "true"
    #
    #   nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
    #   nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    #   or
    #   nginx.ingress.kubernetes.io/auth-type: basic
    #   nginx.ingress.kubernetes.io/auth-secret: auth-secret
    #   nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
    # hosts:
    # - cluster.example.com
    # pathSuffix: ''
    # tls:
    # - secretName: spark-cluster-tls
    #   hosts:
    #   - cluster.example.com

  hub:

    # $> openssl rand -hex 32
    cookieSecret: ""

    resources:
      requests:
        cpu: 200m
        memory: 512Mi

    # image:
    #   name: sasnouskikh/jupyterhub
    #   tag: 0.8.2-azure
    
    # Set up in addition to ingress
    # baseUrl: /jupyterhub
    # publicURL: "https://{your-domain}"
    
    # activeServerLimit: 10

    # Use JupyterLab by default
    # extraConfig:
    #   jupyterlab: |
    #     c.Spawner.cmd = ['jupyter-labhub']

    # For Azure AD OAuthenticator
    # extraEnv:
    #   AAD_TENANT_ID: "{AAD-TENANT-ID}"

    # nodeSelector: {}
    
    # pdb:
    #   enabled: true
    #   minAvailable: 1

  proxy:

    https:
      enabled: false

    # $> openssl rand -hex 32
    secretToken: ""

    service:
      type: ClusterIP
    
    # configurable-http-proxy
    chp:
      resources:
        requests:
          cpu: 200m
          memory: 512Mi

    # nodeSelector: {}

    # pdb:
    #   enabled: true
    #   minAvailable: 1

  auth:

    # Azure AD OAuthenticator
    # type: custom
    # custom:
    #   className: oauthenticator.azuread.AzureAdOAuthenticator
    #   config:
    #     oauth_callback_url: 'https://{your-domain}/hub/oauth_callback'
    #     client_id: '{AAD-APP-CLIENT-ID}'
    #     client_secret: '{AAD-APP-CLIENT-SECRET}'

    type: dummy
    whitelist:
      users:
      - admin
    admin:
      access: true
      users:
      - admin
    dummy:
      password: admin

  singleuser:
    # startTimeout: 300
    # extraEnv:
    #   ENV_NAME: "env-value"
    
    storage:
      capacity: 2Gi
      homeMountPath: /home/jovyan/notebooks
      extraVolumes:
      - name: jupyter-notebooks-default
        configMap:
          name: jupyter-notebooks-default
      # - name: jupyter-notebooks-shared
      #   ...
      extraVolumeMounts:
      - name: jupyter-notebooks-default
        mountPath: /home/jovyan/notebooks/default
        readOnly: true
      # - name: jupyter-notebooks-shared
      #   mountPath: /home/jovyan/notebooks/shared
      #   readOnly: false
    
    image:
      name: jupyter/minimal-notebook
      tag: ae5f7e104dd5
      pullPolicy: IfNotPresent
    
    profileList:

    - display_name: "Minimal environment"
      description: "To avoid too much bells and whistles: Python."
      default: True

    - display_name: "Datascience environment"
      description: "If you want the additional bells and whistles: Python, R, and Julia."
      # https://jupyterhub-kubespawner.readthedocs.io/en/latest/spawner.html#kubespawner.KubeSpawner
      kubespawner_override:
        image: jupyter/datascience-notebook:ae5f7e104dd5
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: "10G"
        mem_limit: "12G"
    
    # https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark
    - display_name: "All notebooks environment"
      description: "If you want to run Apache Spark in Python, R, and Scala notebooks."
      # https://jupyterhub-kubespawner.readthedocs.io/en/latest/spawner.html#kubespawner.KubeSpawner
      kubespawner_override:
        image: jupyter/all-spark-notebook:latest
        cpu_guarantee: 3
        cpu_limit: 4
        mem_guarantee: "10G"
        mem_limit: "12G"
        environment:
          SPARK_DRIVER_MEMORY: "10G"

    - display_name: "Sparkmagic environment"
      description: "The Jupyter Stacks with Sparkmagic image integrated with Livy!"
      # https://jupyterhub-kubespawner.readthedocs.io/en/latest/spawner.html#kubespawner.KubeSpawner
      kubespawner_override:
        image: sasnouskikh/jupyter:4.4.0-sparkmagic_0.12.6
        image_pull_policy: Always
        environment:
          LIVY_ENDPOINT: "http://spark-cluster-livy:80" # is OK if you install chart with name `spark-cluster`
        cmd:
        - /bin/bash
        - -c
        - >
          set -ex;
          sed -i "s|http://localhost:8998|$LIVY_ENDPOINT|g" /home/$NB_USER/.sparkmagic/config.json;
          jupyterhub-singleuser "$@";

    cpu:
      limit: 0.5
      guarantee: 0.25
    memory:
      limit: 2G
      guarantee: 1G
    
    # defaultUrl: "/lab"
    # extraTolerations: []
    # nodeSelector: {}
    # extraNodeAffinity:
    #   required: []
    #   preferred: []
    # extraPodAffinity:
    #   required: []
    #   preferred: []
    # extraPodAntiAffinity:
    #   required: []
    #   preferred: []

  # cull:
  #   enabled: true
  #   users: false
  #   timeout: 3600
  #   every: 600
  #   concurrency: 10
  #   maxAge: 0

  debug:
    enabled: false
